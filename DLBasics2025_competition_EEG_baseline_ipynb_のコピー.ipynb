{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coQMlJO9S5xt"
      },
      "source": [
        "# Deep Learning 基礎講座　最終課題: 脳波分類\n",
        "\n",
        "## 概要\n",
        "被験者が画像を見ているときの脳波から，その画像がどのカテゴリに属するかを分類するタスク．\n",
        "- サンプル数: 訓練 118,800 サンプル，検証 59,400 サンプル，テスト 59,400 サンプル\n",
        "- クラス数: 5\n",
        "- 入力: 脳波データ（チャンネル数 x 系列長）\n",
        "- 出力: 対応する画像のクラス\n",
        "- 評価指標: Top-1 accuracy\n",
        "\n",
        "### 元データセット ([Gifford2022 EEG dataset](https://osf.io/3jk45/)) との違い\n",
        "\n",
        "- 本コンペでは難易度調整の目的で元データセットにいくつかの改変を加えています．\n",
        "\n",
        "1. 訓練セットのみの使用\n",
        "  - 元データセットでは訓練データに存在しなかったクラスの画像を見ているときの脳波においてテストが行われますが，これは難易度が非常に高くなります．\n",
        "  - 本コンペでは元データセットの訓練セットを再分割し，訓練時に存在した画像に対応する別の脳波において検証・テストを行います．\n",
        "\n",
        "2. クラス数の減少\n",
        "  - 元データセット（の訓練セット）では16,540枚の画像に対し，1,654のクラスが存在します．\n",
        "    - e.g. `aardvark`, `alligator`, `almond`, ...\n",
        "  - 本コンペでは1,654のクラスを，`animal`, `food`, `clothing`, `tool`, `vehicle`の5つにまとめています．\n",
        "    - e.g. `aardvark -> animal`, `alligator -> animal`, `almond -> food`, ...\n",
        "\n",
        "### 考えられる工夫の例\n",
        "\n",
        "- 音声モデルの導入\n",
        "  - 脳波と同じ波である音声を扱うアーキテクチャを用いることが有効であると知られています．\n",
        "  - 例）Conformer [[Gulati+ 2020](https://arxiv.org/abs/2005.08100)]\n",
        "- 画像データを用いた事前学習\n",
        "  - 本コンペのタスクは脳波のクラス分類ですが，配布してある画像データを脳波エンコーダの事前学習に用いることを許可します．\n",
        "  - 例）CLIP [Radford+ 2021]\n",
        "  - 画像を用いる場合は[こちら](https://osf.io/download/3v527/)からダウンロードしてください．\n",
        "- 過学習を防ぐ正則化やドロップアウト\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIejJol4XuJO"
      },
      "source": [
        "## 修了要件を満たす条件\n",
        "- ベースラインモデルのbest test accuracyは38.7%となります．**これを超えた提出のみ，修了要件として認めます**．\n",
        "- ベースラインから改善を加えることで，55%までは性能向上することを運営で確認しています．こちらを 1 つの指標として取り組んでみてください．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvF82AJ4YRoI"
      },
      "source": [
        "## 注意点\n",
        "- 学習するモデルについて制限はありませんが，必ず訓練データで学習したモデルで予測してください．\n",
        "    - 事前学習済みモデルを利用して，訓練データを fine-tuning しても構いません．\n",
        "    - 埋め込み抽出モデルなど，モデルの一部を訓練しないケースは構いません．\n",
        "    - 学習を一切せずに，ChatGPT などの基盤モデルを利用することは禁止とします．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGqk3Pi-Qx2i"
      },
      "source": [
        "## 1.準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUe7s_z3-4nX"
      },
      "outputs": [],
      "source": [
        "# omnicampus 実行用\n",
        "!pip install ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUHy4caOQK-r"
      },
      "outputs": [],
      "source": [
        "# ライブラリのインポートとシード固定\n",
        "import os, sys\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from einops.layers.torch import Rearrange\n",
        "from einops import repeat\n",
        "from glob import glob\n",
        "from termcolor import cprint\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "SEED = 0\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqxg06pkE6kT"
      },
      "outputs": [],
      "source": [
        "# ドライブのマウント（Colabの場合）\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yvMbvYiFygT"
      },
      "outputs": [],
      "source": [
        "# ワーキングディレクトリを作成し移動．ノートブックを配置したディレクトリに適宜書き換え\n",
        "WORK_DIR = \"/content/drive/MyDrive/weblab/DLBasics2025/Competition\"\n",
        "os.makedirs(WORK_DIR, exist_ok=True)\n",
        "%cd {WORK_DIR}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRPCgb3UQnRs"
      },
      "source": [
        "## 2.データセット"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eMvZ7FcIb9_"
      },
      "source": [
        "ノートブックと同じディレクトリに`data/`が存在することを確認してください．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hq0lx0SdY7g"
      },
      "outputs": [],
      "source": [
        "class ThingsEEGDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, split: str) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        assert split in [\"train\", \"val\", \"test\"], f\"Invalid split: {split}\"\n",
        "        self.split = split\n",
        "        self.num_classes = 5\n",
        "        self.num_subjects = 10\n",
        "\n",
        "        self.X = np.load(f\"data/{split}/eeg.npy\")\n",
        "        self.X = torch.from_numpy(self.X).to(torch.float32)\n",
        "        self.subject_idxs = np.load(f\"data/{split}/subject_idxs.npy\")\n",
        "        self.subject_idxs = torch.from_numpy(self.subject_idxs)\n",
        "\n",
        "        if split in [\"train\", \"val\"]:\n",
        "            self.y = np.load(f\"data/{split}/labels.npy\")\n",
        "            self.y = torch.from_numpy(self.y)\n",
        "\n",
        "        print(f\"EEG: {self.X.shape}, labels: {self.y.shape if hasattr(self, 'y') else None}, subject indices: {self.subject_idxs.shape}\")\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        if hasattr(self, \"y\"):\n",
        "            return self.X[i], self.y[i], self.subject_idxs[i]\n",
        "        else:\n",
        "            return self.X[i], self.subject_idxs[i]\n",
        "\n",
        "    @property\n",
        "    def num_channels(self) -> int:\n",
        "        return self.X.shape[1]\n",
        "\n",
        "    @property\n",
        "    def seq_len(self) -> int:\n",
        "        return self.X.shape[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qf_SIweQb2l"
      },
      "source": [
        "## 3.ベースラインモデル"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HhAzFNRQdgH"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_dim,\n",
        "        out_dim,\n",
        "        kernel_size: int = 3,\n",
        "        p_drop: float = 0.1,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_dim = in_dim\n",
        "        self.out_dim = out_dim\n",
        "\n",
        "        self.conv0 = nn.Conv1d(in_dim, out_dim, kernel_size, padding=\"same\")\n",
        "        self.conv1 = nn.Conv1d(out_dim, out_dim, kernel_size, padding=\"same\")\n",
        "        # self.conv2 = nn.Conv1d(out_dim, out_dim, kernel_size) # , padding=\"same\")\n",
        "\n",
        "        self.batchnorm0 = nn.BatchNorm1d(num_features=out_dim)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(num_features=out_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(p_drop)\n",
        "\n",
        "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
        "        if self.in_dim == self.out_dim:\n",
        "            X = self.conv0(X) + X  # skip connection\n",
        "        else:\n",
        "            X = self.conv0(X)\n",
        "\n",
        "        X = F.gelu(self.batchnorm0(X))\n",
        "\n",
        "        X = self.conv1(X) + X  # skip connection\n",
        "        X = F.gelu(self.batchnorm1(X))\n",
        "\n",
        "        # X = self.conv2(X)\n",
        "        # X = F.glu(X, dim=-2)\n",
        "\n",
        "        return self.dropout(X)\n",
        "\n",
        "\n",
        "class BasicConvClassifier(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes: int,\n",
        "        seq_len: int,\n",
        "        in_channels: int,\n",
        "        hid_dim: int = 128\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.blocks = nn.Sequential(\n",
        "            ConvBlock(in_channels, hid_dim),\n",
        "            ConvBlock(hid_dim, hid_dim),\n",
        "        )\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool1d(1),\n",
        "            Rearrange(\"b d 1 -> b d\"),\n",
        "            nn.Linear(hid_dim, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"_summary_\n",
        "        Args:\n",
        "            X ( b, c, t ): _description_\n",
        "        Returns:\n",
        "            X ( b, num_classes ): _description_\n",
        "        \"\"\"\n",
        "        X = self.blocks(X)\n",
        "\n",
        "        return self.head(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWyMO_G1QMvi"
      },
      "source": [
        "## 4.訓練実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5ftIHtyPrSu"
      },
      "outputs": [],
      "source": [
        "# ハイパラ\n",
        "lr = 0.001\n",
        "batch_size = 512\n",
        "epochs = 80\n",
        "\n",
        "# ------------------\n",
        "#    Dataloader\n",
        "# ------------------\n",
        "train_set = ThingsEEGDataset(\"train\") # ThingsMEGDataset(\"train\")\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=batch_size, shuffle=True\n",
        ")\n",
        "val_set = ThingsEEGDataset(\"val\") # ThingsMEGDataset(\"val\")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "# ------------------\n",
        "#       Model\n",
        "# ------------------\n",
        "model = BasicConvClassifier(\n",
        "    train_set.num_classes, train_set.seq_len, train_set.num_channels\n",
        ").to(\"cuda\")\n",
        "\n",
        "# ------------------\n",
        "#     Optimizer\n",
        "# ------------------\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# ------------------\n",
        "#   Start training\n",
        "# ------------------\n",
        "max_val_acc = 0\n",
        "def accuracy(y_pred, y):\n",
        "    return (y_pred.argmax(dim=-1) == y).float().mean()\n",
        "\n",
        "writer = SummaryWriter(\"tensorboard\")\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
        "\n",
        "    model.train()\n",
        "    for X, y, subject_idxs in tqdm(train_loader, desc=\"Train\"):\n",
        "        X, y = X.to(\"cuda\"), y.to(\"cuda\")\n",
        "\n",
        "        y_pred = model(X)\n",
        "\n",
        "        loss = F.cross_entropy(y_pred, y)\n",
        "        train_loss.append(loss.item())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = accuracy(y_pred, y)\n",
        "        train_acc.append(acc.item())\n",
        "\n",
        "    model.eval()\n",
        "    for X, y, subject_idxs in tqdm(val_loader, desc=\"Validation\"):\n",
        "        X, y = X.to(\"cuda\"), y.to(\"cuda\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(X)\n",
        "\n",
        "        val_loss.append(F.cross_entropy(y_pred, y).item())\n",
        "        val_acc.append(accuracy(y_pred, y).item())\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | \\\n",
        "        train loss: {np.mean(train_loss):.3f} | \\\n",
        "        train acc: {np.mean(train_acc):.3f} | \\\n",
        "        val loss: {np.mean(val_loss):.3f} | \\\n",
        "        val acc: {np.mean(val_acc):.3f}\")\n",
        "\n",
        "    writer.add_scalar(\"train_loss\", np.mean(train_loss), epoch)\n",
        "    writer.add_scalar(\"train_acc\", np.mean(train_acc), epoch)\n",
        "    writer.add_scalar(\"val_loss\", np.mean(val_loss), epoch)\n",
        "    writer.add_scalar(\"val_acc\", np.mean(val_acc), epoch)\n",
        "\n",
        "    torch.save(model.state_dict(), \"model_last.pt\")\n",
        "\n",
        "    if np.mean(val_acc) > max_val_acc:\n",
        "        cprint(\"New best. Saving the model.\", \"cyan\")\n",
        "        torch.save(model.state_dict(), \"model_best.pt\")\n",
        "        max_val_acc = np.mean(val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PEUGAd6McTY"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJK_TDK3ZC59"
      },
      "source": [
        "## 5.評価"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLQswnBMY_gD"
      },
      "outputs": [],
      "source": [
        "# ------------------\n",
        "#    Dataloader\n",
        "# ------------------\n",
        "test_set = ThingsEEGDataset(\"test\")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=batch_size, shuffle=False\n",
        ")\n",
        "\n",
        "# ------------------\n",
        "#       Model\n",
        "# ------------------\n",
        "model = BasicConvClassifier(\n",
        "    test_set.num_classes, test_set.seq_len, test_set.num_channels\n",
        ").to(\"cuda\")\n",
        "model.load_state_dict(torch.load(\"model_best.pt\", map_location=\"cuda\"))\n",
        "\n",
        "# ------------------\n",
        "#  Start evaluation\n",
        "# ------------------\n",
        "preds = []\n",
        "model.eval()\n",
        "for X, subject_idxs in tqdm(test_loader, desc=\"Evaluation\"):\n",
        "    preds.append(model(X.to(\"cuda\")).detach().cpu())\n",
        "\n",
        "preds = torch.cat(preds, dim=0).numpy()\n",
        "np.save(\"submission\", preds)\n",
        "print(f\"Submission {preds.shape} saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSuRjyoDihdK"
      },
      "source": [
        "## 提出方法\n",
        "\n",
        "以下の3点をzip化し，Omnicampusの「最終課題 (EEG)」から提出してください．\n",
        "\n",
        "- `submission.npy`\n",
        "- `model_last.pt`や`model_best.pt`など，テストに使用した重み（拡張子は`.pt`のみ）\n",
        "- 本Colab Notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlrJFVFQ33nF"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "model_path = \"model_best.pt\"\n",
        "notebook_path = \"DLBasics2025_competition_EEG_baseline.ipynb\"\n",
        "\n",
        "with ZipFile(\"submission.zip\", \"w\") as zf:\n",
        "    zf.write(\"submission.npy\")\n",
        "    zf.write(model_path)\n",
        "    zf.write(notebook_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhBI_Tz2-4nc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}